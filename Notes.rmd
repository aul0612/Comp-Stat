---
title: "Notes"
output: 
  html_document:
    code_folding: show
    theme:
      bg: "#202123"
      fg: "#B8BCC2"
      primary: "#EA80FC"
      secondary: "#00DAC6"
      base_font:
        google: Prompt
      heading_font:
        google: Proza Libre
---

```{r setup, include=FALSE}
if (requireNamespace("thematic")) 
  thematic::thematic_rmd(font = "auto")
```
# 25.04.2024
## 2.3 The true view on the EM-Algorithm
### 2.3.1
${P(Z_{ig} = 1) = \pi{_g}}$, but ${\pi_g}$ ist still unknown, as it is one parameter, we want to estimate.

### 2.3.2
Expectation comes in from the posterior probabilities which is equal to a conditional mean since $Z_ig$ is binary.

### 2.3.3
If we maximize log-likelihood for each group individually, no singularities will appear.

We don't know, $Z_{ig}$, so we predict it as a conditional expected value.
This, then is just $p_{ig}$, since the posterior probability is just a conditional expected value.

We first calculate an expected log-likelihood function, where posterior is predictor of latent variable.
Then, we maximize over the parameters, and update our guesses (including the prior distribution) of the parameters.
Then, loop.


# 06.05.2024
## 3.2 Recap
ECDF ($F_n$) is a random function.
right-continuous
ECDF is distribution function of $X^*$ where $X^*$ is discrete with the values we observed.
Random sample comes from random variable X, our ECDF uses $X^*$ which comes from our random sample.
Idea: X ~ F. we cannot sample from F, but we can resample from a distribution with ECDF.
Glivenko-Cantelli-Theorem implies pointwise convergence.

Bootstrap sampling is sampling from the original sample with replacement.
Resampling m times a Bootstrap sample of size n.
with large m theta hat asterisk n is approximating sample well. If initial sample size n is large enough, it is by asymptotic arguments also informative of the population.
Bootstrap is nonparametric because F is not parameterized (there is a parametrical Bootstrap, which is not used often since it requires distributional assumptions on F).
$S_n$ can be either a random sample or the realization of it.


# 13.05.2024
The ECDF is binomial regardless of the actual distribution of X. -> "distribution-free"
That is because rank-statistics are distribution-free

## Exercises Chapter 2

you could use that to conduct cluster Analysis on mnist

## 3.4 The Basic Bootstrap Method

We do as if we know $H_n^{Boot}$, although it is a population version. Since we can choose m arbitrarily large sample version $H_{n,m}^{Boot}$ is arbitrarily good approximation.

# 27.05.2024
we can take the sum out of the variance since we have iid data and thus, the covariances are zero.
big O -> LHS has same order of magnitude
small o -> LHS has smaller order of magnitude
